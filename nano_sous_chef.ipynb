{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "\n",
    "load_dotenv()\n",
    "pc = Pinecone(api_key=getenv('PINECONE_API_KEY'))\n",
    "index = pc.Index('nano-sous-chef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "creative_llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "strict_llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_llm.invoke('What is a train?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db = sqlite3.connect('cookbook.db')\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# ingredients chain\n",
    "ingredients_system_prompt = '''\n",
    "You are a chef's digital assistant, and you were just provided with some text.\n",
    "Extract a list of all of the ingredients mentioned and return it structured in JSON format.\n",
    "I only want the name of the ingredient.\n",
    "Make sure to capitalize the first letter of every word.\n",
    "'''\n",
    "\n",
    "ingredients_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", ingredients_system_prompt),\n",
    "    (\"user\", \"{user_prompt}\")\n",
    "])\n",
    "\n",
    "ingredients_chain = ingredients_prompt_template | strict_llm | JsonOutputParser()\n",
    "\n",
    "def ingredients_node(src):\n",
    "    return ingredients_chain.invoke({'user_prompt' : src})['ingredients']\n",
    "\n",
    "# example\n",
    "# print(ingredients_node('I have eggs, cabbages, and strawberries in my pantry.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# exit station\n",
    "terminal_system_prompt = '''\n",
    "Determine whether the user would like to 'try again' or 'exit', based on the input given.\n",
    "Categorize what they said as either one, and only return that answer. If the user doesn't seem to reflect\n",
    "intent to try again, respond with 'exit' regardless.\n",
    "'''\n",
    "\n",
    "terminal_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", terminal_system_prompt),\n",
    "    (\"user\", \"{user_prompt}\")\n",
    "])\n",
    "\n",
    "terminal_chain = terminal_prompt_template | strict_llm | StrOutputParser()\n",
    "\n",
    "def terminal_node(negative_outcome=False):\n",
    "    if negative_outcome:\n",
    "        print('\\n\\nSorry I wasn\\'t able to help with that last query! Would you like to try again or exit?\\n')\n",
    "    else:\n",
    "        print('\\n\\nThanks for trying out my system! Would you like to try again or exit?\\n')\n",
    "    response = input()\n",
    "    intent = terminal_chain.invoke({'user_prompt' : response})\n",
    "    if intent == 'try again':\n",
    "        print('Wants to try again, not implemented yet!')\n",
    "        # TODO invoke genesis from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full description chain\n",
    "def collect_information(id):\n",
    "    res = []\n",
    "    cursor.execute('''\n",
    "        SELECT name, aggregated_rating, recipe_servings, recipe_yield, recipe_instructions,\n",
    "            cook_time, prep_time, total_time FROM information where id = {};\n",
    "                   '''.format(id))\n",
    "    res.append(cursor.fetchone())\n",
    "    cursor.execute('''\n",
    "        SELECT * from macros WHERE recipe_id={};\n",
    "                   '''.format(id))\n",
    "    res.append(cursor.fetchone())\n",
    "    cursor.execute('''\n",
    "        SELECT * from ingredient_recipe WHERE recipe_id={};\n",
    "                   '''.format(id))\n",
    "    res.append(cursor.fetchall())\n",
    "    return res\n",
    "\n",
    "full_description_system_prompt = '''\n",
    "You are a chef's digital assistant, and you were just provided with text that has all the information\n",
    "about a particular dish. Using the information provided, provide a detailed description of the dish itself,\n",
    "before describing how to make it as per the information provided.\n",
    "\n",
    "Structure your response as if it's an entry in a recipe book, and make it clear and easy to follow.\n",
    "'''\n",
    "\n",
    "full_description_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", full_description_system_prompt),\n",
    "    (\"user\", \"{dish_info}\")\n",
    "])\n",
    "\n",
    "full_description_chain = full_description_prompt_template | creative_llm\n",
    "\n",
    "def full_description_node(id):\n",
    "    info = collect_information(id)\n",
    "    # res = full_description_chain.invoke({'dish_info' : info})\n",
    "    # print(res, '\\n')\n",
    "\n",
    "    for chunk in full_description_chain.stream({'dish_info' : info}):\n",
    "        print(chunk.content, end='', flush=True)\n",
    "\n",
    "    terminal_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_description_header(desc):\n",
    "    return desc.split('] ')[1]\n",
    "\n",
    "def retrieve_description(index):\n",
    "    cursor.execute(f\"SELECT generated_description FROM generated_descriptions WHERE recipe_id = {index}\")\n",
    "    return trim_description_header(cursor.fetchone()[0])\n",
    "\n",
    "def retrieve_name(index):\n",
    "    cursor.execute(f\"SELECT name FROM information WHERE id = {index}\")\n",
    "    return cursor.fetchone()[0]\n",
    "\n",
    "def generate_dish_list(dishes):\n",
    "    res = ''\n",
    "    i = 1\n",
    "    for id, (name, desc) in dishes.items():\n",
    "        res += (f\"{i}. {name} - {desc}\\n\")\n",
    "        i += 1\n",
    "    return res\n",
    "\n",
    "summarization_categorization_system_prompt = '''\n",
    "You are a chef's digital assistant. The user will provide a list of dishes, followed by a message.\n",
    "Determine the intent behind the message provided, and categorize it as follows:\n",
    "\n",
    "If the user wants to end the run or exit, answer 'exit'.\n",
    "If the user wants to see a full description of a specific dish, return 'full description'.\n",
    "\n",
    "Only answer in the format instructed, and don't have quotes as part of the answer\n",
    "'''\n",
    "\n",
    "dish_picker_system_prompt = '''\n",
    "You are a chef's digital assistant. You'll recieve what a user said, and a list of dishes they picked out from.\n",
    "Return the exact name of the dish they picked out from the options provided. If their response is not clear, return 'unclear'.\n",
    "\n",
    "Only provide either option and nothing else.\n",
    "'''\n",
    "\n",
    "summarization_categorization_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", summarization_categorization_system_prompt),\n",
    "    (\"user\", \"{user_prompt}\")\n",
    "])\n",
    "\n",
    "dish_picker_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", dish_picker_system_prompt),\n",
    "    (\"user\", \"#DISH LIST#\\n{dish_list}\\n\\nUSER MESSAGE: {user_prompt}\")\n",
    "])\n",
    "\n",
    "summarization_categorization_chain = summarization_categorization_prompt_template | strict_llm | StrOutputParser()\n",
    "dish_picker_chain = dish_picker_prompt_template | strict_llm | StrOutputParser()\n",
    "\n",
    "def summarization_node(src):\n",
    "    # a list of ids and their score received\n",
    "    # sort by relevance and remove duplicates\n",
    "    id_to_max_relevance = dict()\n",
    "    for id, relevance in src:\n",
    "        if id not in id_to_max_relevance:\n",
    "            id_to_max_relevance[id] = relevance\n",
    "        else:\n",
    "            id_to_max_relevance[id] = max(id_to_max_relevance[id], relevance)\n",
    "    unique_src = [(k, v) for k, v in id_to_max_relevance.items()]\n",
    "    unique_src.sort(key=lambda x: x[1])\n",
    "    match_ids = [x[0] for x in unique_src]\n",
    "\n",
    "    # pick the top three and retrieve their entries from the RDB.\n",
    "    picks = match_ids[-3:-1]\n",
    "    id_to_name_and_description = dict()\n",
    "    for id in picks:\n",
    "        id_to_name_and_description[id] = (retrieve_name(id), retrieve_description(id))\n",
    "\n",
    "    # output section\n",
    "    print(\"Here are some dishes that come to mind:\\n\\n\")\n",
    "    dish_list = generate_dish_list(id_to_name_and_description)\n",
    "    print(dish_list)\n",
    "    print(\"Would you like to see a full description of any of these, or end this run?\\n\")\n",
    "\n",
    "    user_response = input()\n",
    "    intent = summarization_categorization_chain.invoke({'user_prompt':user_response, 'dish_list':dish_list})\n",
    "    if intent == 'exit':\n",
    "        terminal_node()\n",
    "    else:\n",
    "        picked_dish_name = dish_picker_chain.invoke({'user_prompt':user_response, 'dish_list':dish_list})\n",
    "        if picked_dish_name == 'unclear':\n",
    "            print('I couldn\\'t find that dish.\\n')\n",
    "            terminal_node(negative_outcome=True)\n",
    "            return\n",
    "\n",
    "        picked_dish_id = -1\n",
    "        for id, (name, desc) in id_to_name_and_description.items():\n",
    "            if name == picked_dish_name:\n",
    "                picked_dish_id = id\n",
    "                break\n",
    "        if picked_dish_id == -1:\n",
    "            print('I couldn\\'t find that dish.\\n')\n",
    "            terminal_node(negative_outcome=True)\n",
    "            return\n",
    "        full_description_node(picked_dish_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_vector(v):\n",
    "    return [float(x) for x in v]\n",
    "\n",
    "def find_matches(src_embeddings):\n",
    "    src_embeddings = [fix_vector(v) for v in src_embeddings]\n",
    "    query_responses = []\n",
    "    for v in src_embeddings:\n",
    "        response = index.query(\n",
    "                namespace=\"descriptions\",\n",
    "                vector=v,\n",
    "                top_k=3,\n",
    "                include_values=False,\n",
    "            )\n",
    "        list_form = [(match['id'], match['score']) for match in response['matches']]\n",
    "        query_responses.extend(list_form)\n",
    "    return query_responses\n",
    "\n",
    "def match_retrieval_node(src):\n",
    "    matches = find_matches(src)\n",
    "\n",
    "    if len(matches) == 0:\n",
    "        print('I don\\'t know a dish that matches that description, let\\'s start over')\n",
    "        terminal_node(negative_outcome=True)\n",
    "        return\n",
    "\n",
    "    # generate the response for the dishes found\n",
    "    summarization_node(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embeddings_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "def generate_embeddings_for_generated_descriptions(generated_descriptions):\n",
    "    return list(embeddings_model.encode(generated_descriptions))\n",
    "\n",
    "def embeddings_generation_node(src):\n",
    "    res = generate_embeddings_for_generated_descriptions(src)\n",
    "\n",
    "    match_retrieval_node(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description generation phase chain\n",
    "\n",
    "description_generation_system_prompt = '''\n",
    "You are a chef's digital assistant. You'll be provided with a description of a dish.\n",
    "I want you to generate exactly 3 similar descriptions to the one provided.\n",
    "Make sure that there are exactly 3 generated descriptions.\n",
    "Return the descriptions in JSON. It should be in the format below:\n",
    "descriptions : [x,y,z]\n",
    "'''\n",
    "description_generation_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", description_generation_system_prompt),\n",
    "    (\"user\", \"{user_prompt}\")\n",
    "])\n",
    "\n",
    "description_generation_chain = description_generation_prompt_template | creative_llm | JsonOutputParser()\n",
    "\n",
    "def description_generation_helper(src):\n",
    "    res = description_generation_chain.invoke({'user_prompt' : src})\n",
    "    return res['descriptions'] + [src]\n",
    "\n",
    "def description_generation_node(src):\n",
    "    res = description_generation_helper(src)\n",
    "\n",
    "    # send to embeddings generation\n",
    "    embeddings_generation_node(res)\n",
    "\n",
    "# example\n",
    "description_generation_node(\n",
    "    'The dish I have in mind is biryani.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# genesis chain\n",
    "genesis_system_prompt = '''\n",
    "You are a chef's digital assistant. You'll recieve a prompt from the chef and your\n",
    "job is to classify the prompt into the category it fits into.\n",
    "\n",
    "The category names are:\n",
    "dish description\n",
    "ingredient list\n",
    "\n",
    "Respond with only the category name.\n",
    "'''\n",
    "\n",
    "genesis_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", genesis_system_prompt),\n",
    "    (\"user\", \"{user_prompt}\")\n",
    "])\n",
    "\n",
    "genesis_chain = genesis_prompt_template | strict_llm | StrOutputParser()\n",
    "\n",
    "# example case\n",
    "# print(genesis_chain.invoke({'user_prompt':'tuna'}))\n",
    "# print(genesis_chain.invoke({'user_prompt':'tuna sandwich'}))\n",
    "\n",
    "genesis_opener = '''\n",
    "Hey, I\\'m nano sous chef. Let\\'s create an amazing dish!\n",
    "\n",
    "You can either give me the name or description of the dish you have in mind,\n",
    "or a list of what ingredients you have so I can suggest some possible dishes from what I know!\\n\n",
    "'''\n",
    "\n",
    "def genesis_node():\n",
    "    print(genesis_opener)\n",
    "    user_input = input()\n",
    "    if genesis_chain.invoke(user_input) == 'ingredient list':\n",
    "        ingredients_node(user_input)\n",
    "    else:\n",
    "        description_generation_node(user_input)\n",
    "# example\n",
    "# print(genesis_node())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genesis_node()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
